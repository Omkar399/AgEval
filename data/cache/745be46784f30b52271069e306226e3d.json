{
  "timestamp": "2025-05-31T19:47:59.642743",
  "data": "```json\n[\n  {\n    \"name\": \"Correctness\",\n    \"definition\": \"Assess whether the agent's output is factually correct and accurately addresses all aspects of the prompt.  This requires human judgment and may involve partial credit.\",\n    \"scale\": \"Numeric\"\n  },\n  {\n    \"name\": \"Completeness\",\n    \"definition\": \"Measure the extent to which the agent's response fulfills all requirements specified in the prompt.  A score of 1 indicates complete fulfillment, while 0 indicates no fulfillment, with intermediate values representing partial fulfillment.\",\n    \"scale\": \"Numeric\"\n  },\n  {\n    \"name\": \"Coherence\",\n    \"definition\": \"Evaluate the logical flow and organization of the agent's response.  A high score indicates a clear, well-structured, and easy-to-understand response.\",\n    \"scale\": \"Numeric\"\n  },\n  {\n    \"name\": \"Conciseness\",\n    \"definition\": \"Assess whether the agent's response is appropriately concise, avoiding unnecessary verbosity while providing sufficient detail.  Scores range from overly verbose to appropriately concise.\",\n    \"scale\": \"Categorical\"\n  },\n  {\n    \"name\": \"Efficiency\",\n    \"definition\": \"Measure the computational or time efficiency of the agent's solution (if applicable).  This could involve assessing the number of steps, API calls, or processing time.\",\n    \"scale\": \"Numeric\"\n  }\n]\n```\n"
}