{
  "timestamp": "2025-05-31T19:19:20.329155",
  "data": "[\n  {\n    \"name\": \"Answer Accuracy\",\n    \"definition\": \"Measure whether the Agent's final output correctly and completely addresses the core task requirements, based on ground truth or expected results.\",\n    \"scale\": \"Binary\"\n  },\n  {\n    \"name\": \"Response Completeness\",\n    \"definition\": \"Evaluate if the Agent's output includes all necessary components or steps requested by the prompt, without missing critical information.\",\n    \"scale\": \"Categorical\"\n  },\n  {\n    \"name\": \"Instruction Adherence\",\n    \"definition\": \"Assess how well the Agent follows explicit instructions or constraints given in the prompt, such as formatting, API usage, or output style.\",\n    \"scale\": \"Categorical\"\n  },\n  {\n    \"name\": \"Clarity and Coherence\",\n    \"definition\": \"Rate the clarity, logical flow, and understandability of the Agent's response, regardless of task type.\",\n    \"scale\": \"Categorical\"\n  },\n  {\n    \"name\": \"Error Handling and Robustness\",\n    \"definition\": \"Determine if the Agent appropriately handles potential errors, edge cases, or ambiguous inputs within the task context.\",\n    \"scale\": \"Categorical\"\n  }\n]"
}