#!/bin/bash
# Quick start script for AgEval - Three-Judge AI Evaluation System

set -e

echo "ğŸš€ AgEval Quick Start Setup"
echo "=========================="

# Check if Python 3 is available
if ! command -v python3 &> /dev/null; then
    echo "âŒ Python 3 is required but not installed. Please install Python 3.8 or later."
    exit 1
fi

echo "âœ… Python 3 found: $(python3 --version)"

# Create virtual environment if it doesn't exist
if [ ! -d "venv" ]; then
    echo "ğŸ“¦ Creating virtual environment..."
    python3 -m venv venv
else
    echo "âœ… Virtual environment already exists"
fi

# Activate virtual environment
echo "ğŸ”§ Activating virtual environment..."
source venv/bin/activate

# Install dependencies
echo "ğŸ“¥ Installing dependencies..."
pip install -r requirements.txt

# Create necessary directories
echo "ğŸ“ Creating directories..."
mkdir -p logs reports data/cache

# Check if configuration exists
if [ ! -f "config/judges_config.yaml" ]; then
    echo "âš™ï¸  Creating configuration file..."
    cp config/judges_config.yaml.example config/judges_config.yaml
    echo "ğŸ“ Please edit config/judges_config.yaml and add your API keys:"
    echo "   - OpenAI API key for JudgeA and JudgeC"
    echo "   - Anthropic API key for JudgeB"
    echo "   - API key for the agent being evaluated"
else
    echo "âœ… Configuration file already exists"
fi

# Test basic functionality
echo "ğŸ§ª Testing basic functionality..."
python run_evaluation.py --phase 1

echo ""
echo "ğŸ‰ Setup completed successfully!"
echo ""
echo "Next steps:"
echo "1. Edit config/judges_config.yaml with your API keys"
echo "2. Run a full evaluation: python run_evaluation.py"
echo "3. Generate reports: python generate_report.py"
echo ""
echo "For help: python run_evaluation.py --help"
echo "Documentation: See README.md and docs/ directory" 